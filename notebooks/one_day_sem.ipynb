{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/data/tmp/one_day/’: File exists\n",
      "mkdir: cannot create directory ‘/data/tmp/one_day/28_02_2020/’: File exists\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tools\n",
    "\n",
    "# init paths to data and models\n",
    "DATA_PATH = '/data/'\n",
    "\n",
    "SEM_MODEL_NAME = 'sm_wv4_ru_norm'\n",
    "OPT_SEM = 100\n",
    "SEM_MODEL_PATH = DATA_PATH + f'models/{SEM_MODEL_NAME}/'\n",
    "IDS_PATH = DATA_PATH + 'psql/spb_posts_28_02_2020.csv'\n",
    "POST_PATH = DATA_PATH + 'captions/lem/spb_posts_2020.csv'\n",
    "DATE = '28_02_2020'\n",
    "TMP_PATH = f'{DATA_PATH}tmp/one_day/'\n",
    "!mkdir {TMP_PATH}\n",
    "FULL_PATH = f'{TMP_PATH}{DATE}/'\n",
    "!mkdir {FULL_PATH}\n",
    "n_clusters = list(range(5, 251))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGPASSWORD=secretpwd psql -h 10.9.14.132 -U secretuser -d spb -c \"\\copy (select shortcode as code from posts where timestamp between 1582848000 and 1582934400) to 'spb_posts_28_02_2020.csv' csv header;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts in day: 21806\n",
      "posts in year: 2353209\n",
      "non empty posts: 18925\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(IDS_PATH)\n",
    "ids = set(df['code'].tolist())\n",
    "print(f'posts in day: {len(ids)}')\n",
    "\n",
    "df = pd.read_csv(POST_PATH)\n",
    "print(f'posts in year: {len(df)}')\n",
    "\n",
    "df = df[df['code'].isin(ids)]\n",
    "print(f'non empty posts: {len(df)}')\n",
    "\n",
    "!mkdir {TMP_PATH}\n",
    "df.to_csv(r'' + TMP_PATH + 'df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'' + FULL_PATH + 'df_lemmed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/data/tmp/one_day/28_02_2020/’: File exists\r\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5b661d21eece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mis_not_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOPT_SEM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "df_words = pd.read_csv(SEM_MODEL_PATH)\n",
    "\n",
    "\n",
    "# calculate semantic vectors for events\n",
    "X = []\n",
    "is_not_empty = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    vec = np.zeros(OPT_SEM)\n",
    "    words = list(filter(lambda w: w in w2l, row.caption.split()))\n",
    "    for word in words:\n",
    "        vec[w2l[word]] += 1\n",
    "    \n",
    "    if len(words) > 0:\n",
    "        X.append(vec / len(words))\n",
    "        is_not_empty.append(True)\n",
    "    else:\n",
    "        is_not_empty.append(False)\n",
    "        \n",
    "X = np.array(X)\n",
    "df = df[is_not_empty]\n",
    "print(f'non empty after filtering words: {len(df)}')\n",
    "\n",
    "# scaling of semantic vectors\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "    \n",
    "\n",
    "# calculate 2d embeding for events\n",
    "tsne = TSNE(n_components=2, random_state=0, n_jobs=35, early_exaggeration=10, learning_rate=200)\n",
    "X_2d = tsne.fit_transform(X) \n",
    "x_vals, y_vals = list(zip(*X_2d))\n",
    "df['x'] = x_vals\n",
    "df['y'] = y_vals\n",
    "\n",
    "df.to_csv(r'' + TMP_PATH + 'df.csv', index=False)\n",
    "np.save(TMP_PATH + 'X.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(FULL_PATH + 'X.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9990891250458485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.999089125045849"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[1]\n",
    "print(np.sqrt((x ** 2).sum()))\n",
    "np.linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row_len = 80\n",
    "rows_hover_name = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    hover_name = ''\n",
    "    row_len = 0\n",
    "    words = row.caption.split()\n",
    "    for word in words:\n",
    "        if row_len + len(word) > max_row_len:\n",
    "            hover_name += '<br>'\n",
    "            row_len = 0\n",
    "        hover_name += word + ' '\n",
    "        row_len += len(word) + 1\n",
    "    rows_hover_name.append(hover_name)\n",
    "df['hover_name'] = rows_hover_name      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_hover_tags = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    hover_tags = ''\n",
    "    words = row.caption.split()\n",
    "    for word in words:\n",
    "        if word[0] != '#' and word[0] != '@':\n",
    "            continue\n",
    "        hover_tags += word + '<br>'\n",
    "    rows_hover_tags.append(hover_tags)\n",
    "df['hover_tags'] = rows_hover_tags  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "print(len(df))\n",
    "px.scatter(df, x='x', y='y', hover_name='hover_name').show()\n",
    "\n",
    "df_tmp = df[~(df['hover_tags'] == '')]\n",
    "print(len(df_tmp))\n",
    "px.scatter(df_tmp, x='x', y='y', hover_name='hover_tags').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tools.agglomerative_list(n_clusters, df, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ca869f86a68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "df_centroids = pd.DataFrame([], columns=['x', 'y', 'label', 'hover_name', 'name', 'size'])\n",
    "top_words = 20\n",
    "n_clusters = 75\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster = df[df[str(n_clusters)] == i]\n",
    "    x = cluster['x'].mean()\n",
    "    y = cluster['y'].mean()\n",
    "    t = ' '.join(cluster['caption'])\n",
    "        \n",
    "    name = Counter(t.split()).most_common(top_words)\n",
    "    hover_name = '<br>'.join(map(itemgetter(0), name))\n",
    "    df_centroids.loc[len(df_centroids)] = [x, y, float(i), hover_name, name, np.int64(len(cluster))]\n",
    "\n",
    "df_centroids['size'] = df_centroids['size'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b2e301a5c1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhover_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hover_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_centroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_centroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hover_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'<br>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<br>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_centroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhover_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hover_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "px.scatter(df, x='x', y='y', color=str(n_clusters), hover_name='hover_name').show()\n",
    "\n",
    "df_centroids['text'] = df_centroids['hover_name'].apply(lambda s: '<br>'.join(s.split('<br>')[:1]))\n",
    "px.scatter(df_centroids, x=\"x\", y=\"y\", color='label', text='text', size='size', hover_name='hover_name', size_max=80).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63d2b6eedae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "IDF_PATH = f'{DATA_PATH}captions/idf_ru.txt'\n",
    "with open(IDF_PATH, 'r') as f:\n",
    "    idf = dict(map(lambda p: (p[0], float(p[1])), [line.split(',') for line in f]))\n",
    "    \n",
    "from operator import itemgetter\n",
    "top = 20\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    cluster = df[df[str(n_clusters)] == i]\n",
    "    x = cluster['x'].mean()\n",
    "    y = cluster['y'].mean()\n",
    "    # counting words from document, which have vector in Word Embedding Model\n",
    "    tf = Counter(filter(lambda w: (w in wv.vocab) and (w in idf), document.split()))\n",
    "    # calculating tf-idf \n",
    "    tf_idf = [(w, tf[w] * idf[w]) for w in tf]\n",
    "    top_words = sorted(tf_idf, key=itemgetter(1), reverse=True)[:top]\n",
    "    # sorting words of the document by tf_idf and slicing top of them\n",
    "    hover_name = '<br>'.join([f'{w}: {s}' for w, s in top_words])\n",
    "    \n",
    "    t = ' '.join(cluster['caption'])\n",
    "        \n",
    "    name = [w for w, s in top_words]\n",
    "    df_centroids.loc[len(df_centroids)] = [x, y, float(i), hover_name, name, np.int64(len(cluster))]\n",
    "    \n",
    "df_centroids['size'] = df_centroids['size'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
