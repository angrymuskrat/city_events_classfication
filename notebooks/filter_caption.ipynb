{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "filter_caption.ipynb",
   "provenance": [],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyMZsRMlgE+83bZ7K7jNXAb5"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ymw4CB2EH4Q",
    "colab_type": "text"
   },
   "source": [
    "firstly load data from gdrive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f_gq-hpeDHu4",
    "colab_type": "code",
    "outputId": "f6f95c88-38a9-4c6f-b2d0-f58ad3cb0247",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586262978862,
     "user_tz": -180,
     "elapsed": 31366,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# this for google colab\n",
    "# !wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "# !tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "# !cp mystem /bin\n",
    "from pymystem3 import Mystem\n",
    "my_stem = Mystem()\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gec_EjMzEXcg",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum\n",
    "\n",
    "# DATA_PATH = 'drive/My Drive/data/'\n",
    "DATA_PATH = '/data/hdd/mkov/events/data/'\n",
    "ROW_CAPTION_PATH = DATA_PATH + 'row-caption/'\n",
    "CAPTION_PATH = DATA_PATH + 'caption/'\n",
    "CAPTIONS = ['posts2016.csv', 'posts2017.csv', 'posts2018.csv', 'posts2019.csv', 'posts2020.csv']\n",
    "\n",
    "MIN_DOCUMENT_SIZE = 1\n",
    "HASH_DELIMITER = 'ЙWЙ'\n",
    "\n",
    "useless_symbols = set(['_', 'ー'])\n",
    "filter_words = set()\n",
    "# load stopwords from nltk\n",
    "filter_words = filter_words.union(set(stopwords.words('english')))\n",
    "filter_words = filter_words.union(set(stopwords.words('russian')))\n",
    "# load own stopwords\n",
    "with open('../src/stopwords.txt') as f:\n",
    "    filter_words = filter_words.union(set([word for line in f for word in line.split()]))\n",
    "\n",
    "\n",
    "# input: document: str\n",
    "# output: document: str\n",
    "# make preprocessing of documents, remove useless symbols, remove useless words\n",
    "def preprocessor(s: str):\n",
    "  # all letter to lower case\n",
    "  s = s.lower() \n",
    "  # save '#' symbol\n",
    "  s = s.replace('#', HASH_DELIMITER)\n",
    "  # remove all symbol, which aren't letter or num\n",
    "  s = strip_non_alphanum(s)\n",
    "  # strip_non_alphanum don't remove '_' symbol\n",
    "  s = ''.join(map(lambda c: ' ' if c in useless_symbols else c))\n",
    "  # restore '#' symbol\n",
    "  s = s.replace(HASH_DELIMITER, ' #')\n",
    "  \n",
    "  #s = ''.join(my_stem.lemmatize(s))\n",
    "  # replace all space symbol like space, tab, \\n to simple space and remove double and for space\n",
    "  s = strip_multiple_whitespaces(s)\n",
    "  # remove empty words and words from filtered words \n",
    "  s = ' '.join(list(filter(lambda w:  len(w) > 0 and (not w in filter_words), s.split(' '))))\n",
    "  return s\n",
    "\n",
    "not_use_preprocess = True\n",
    "\n",
    "for post_file in CAPTIONS:\n",
    "  if not_use_preprocess:\n",
    "    break\n",
    "  # load file and drop documents with empty text\n",
    "  df = pd.read_csv(ROW_CAPTION_PATH + post_file).dropna()\n",
    "  # preprocess of corpus\n",
    "  df['caption'] = df['caption'].apply(preprocessor)\n",
    "  # remove empty documents\n",
    "  df = df[df['caption'].map(len) > MIN_DOCUMENT_SIZE]\n",
    "  # save results\n",
    "  df.to_csv(r'' + CAPTION_PATH + post_file, index=False)\n",
    "  print(\"finished \" + post_file)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClNISbTos-PL",
    "colab_type": "text"
   },
   "source": [
    "Вместо леммитицазии всех докуентов поотдельности можно обработать весь текст, после составить словарь всех слов, леммитизировать все по одному разу и перезаписать текст постов\n",
    "\n",
    "* pymystem3 - not very fast\n",
    "* spacy - need to check\n",
    "* pymorphy2 - slow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bUg3MpFVfaGG",
    "colab_type": "code",
    "outputId": "76049a06-47d7-426b-c8f8-8cce57a0e4c9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586265073616,
     "user_tz": -180,
     "elapsed": 1803670,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# fast lemmatize\n",
    "from collections import defaultdict\n",
    "LEM_CAPTION_PATH = DATA_PATH + 'lem-caption/'\n",
    "\n",
    "d = defaultdict(int)\n",
    "data = range(len(CAPTIONS))\n",
    "f = open(DATA_PATH + 'dictionary.txt', 'w')\n",
    "\n",
    "# load all words to dictionary\n",
    "for i in data:\n",
    "  df = pd.read_csv(CAPTION_PATH + CAPTIONS[i])\n",
    "\n",
    "  for text in df['caption']:\n",
    "    words = text.split(' ')\n",
    "    for word in words:\n",
    "      d[word] += 1\n",
    "\n",
    "\n",
    "# create lemmatized dictionary\n",
    "d_lem = { word: ''.join(my_stem.lemmatize(word)[:-1]) for word in d } # [:-1] for remove \\n after lemmatize\n",
    "\n",
    "# save dictionary \n",
    "for word in d:\n",
    "  f.write(word + ',' + d_lem[word] + ',' + str(d[word]) + '\\n')\n",
    "f.close()\n",
    "\n",
    "# replece all words in dataset to lemmatized words\n",
    "for i in data:\n",
    "  df = pd.read_csv(CAPTION_PATH + CAPTIONS[i])\n",
    "\n",
    "  df['caption'] = df['caption'].apply(lambda caption: ' '.join(list(map(lambda word: d_lem[word], caption.split(' ')))))\n",
    "\n",
    "  df.to_csv(r'' + LEM_CAPTION_PATH + CAPTIONS[i], index=False)\n",
    "  print(\"finished \" + CAPTIONS[i])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F-NJgdVAw9GK",
    "colab_type": "code",
    "outputId": "ce50ad29-9f62-4604-b688-99026a1eb366",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586267032890,
     "user_tz": -180,
     "elapsed": 30814,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "with open(DATA_PATH + 'dictionary.txt') as f:\n",
    "  d_list = [[token for token in line.split(',')] for line in f]\n",
    "\n",
    "\n",
    "d_lem = defaultdict(int)\n",
    "\n",
    "\n",
    "for note in d_list:\n",
    "  d_lem[note[1]] += int(note[2])\n",
    "\n",
    "l = list(d_lem.items())   \n",
    "l.sort(reverse=True, key=lambda item: item[1])\n",
    "\n",
    "print(len(l))\n",
    "l = list(filter(lambda item: item[1] > 1, l))\n",
    "print(len(l))\n",
    "\n",
    "for i in range(500):\n",
    "    print(i, l[i])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NsP1pyDcCQX6",
    "colab_type": "code",
    "outputId": "58ad56b4-dd07-4ffa-ca60-36494f4828ab",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586253510622,
     "user_tz": -180,
     "elapsed": 924,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "text = 'ー_фы'\n",
    "text2 = 'df_tf'\n",
    "print(str(map(lambda c: c = ' ' if c in )))\n",
    "print(my_stem.lemmatize(text))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}