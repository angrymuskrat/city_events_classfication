{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "5ymw4CB2EH4Q"
   },
   "source": [
    "init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31366,
     "status": "ok",
     "timestamp": 1586262978862,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     },
     "user_tz": -180
    },
    "id": "f_gq-hpeDHu4",
    "outputId": "f6f95c88-38a9-4c6f-b2d0-f58ad3cb0247",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "my_stem = Mystem()\n",
    "\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    nltk.corpus.stopwords.words('english')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import gensim.models\n",
    "\n",
    "DATA_PATH = '/data/'\n",
    "CAPTION_PATH = DATA_PATH + 'captions/'\n",
    "RAW_CAPTION_PATH = CAPTION_PATH + 'raw/'\n",
    "\n",
    "USE_STOPWORDS = False\n",
    "\n",
    "if USE_STOPWORDS:\n",
    "    ClEAN_CAPTION_PATH = CAPTION_PATH + 'clean_sw/'\n",
    "    LEM_CAPTION_PATH = CAPTION_PATH + 'lem_sw/'\n",
    "else:\n",
    "    ClEAN_CAPTION_PATH = CAPTION_PATH + 'clean/'\n",
    "    LEM_CAPTION_PATH = CAPTION_PATH + 'lem/'\n",
    "\n",
    "cities = ['spb', 'moscow', 'nyc', 'london']\n",
    "years = ['2016', '2017', '2018', '2019', '2020']\n",
    "files = []\n",
    "for city in cities:\n",
    "    for year in years:\n",
    "        files.append([city, year])\n",
    "\n",
    "def csv_path(path, city, year):\n",
    "    return path + city + '_posts_' + year + '.csv'\n",
    "\n",
    "\n",
    "import fasttext\n",
    "\n",
    "PRETRAINED_MODEL_PATH = '/data/source/lid.176.bin'\n",
    "lang = fasttext.load_model(PRETRAINED_MODEL_PATH)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell \n",
    "    1. replceces '\\n', tab symbols and other space symbols to simple space\n",
    "    2. removes duplicated spaces \n",
    "    3. removes all symbols, which aren't a letter or space (exception - numbers in a word - '8марта')\n",
    "    4. defines language of posts\n",
    "    5. removes posts without words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gec_EjMzEXcg",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished spb 2016\n",
      "finished spb 2017\n",
      "finished spb 2018\n",
      "finished spb 2019\n",
      "finished spb 2020\n",
      "finished spb; time on stage: 2832.1211614608765; counted posts: 13319020\n",
      "finished moscow 2016\n",
      "finished moscow 2017\n",
      "finished moscow 2018\n",
      "finished moscow 2019\n",
      "finished moscow 2020\n",
      "finished moscow; time on stage: 4025.920019865036; counted posts: 16346499\n",
      "finished nyc 2016\n",
      "finished nyc 2017\n",
      "finished nyc 2018\n",
      "finished nyc 2019\n",
      "finished nyc 2020\n",
      "finished nyc; time on stage: 2517.5023498535156; counted posts: 20386445\n",
      "finished london 2016\n",
      "finished london 2017\n",
      "finished london 2018\n",
      "finished london 2019\n",
      "finished london 2020\n",
      "finished london; time on stage: 1131.6131975650787; counted posts: 9041301\n",
      "completed with time: 10507.157339572906\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "\n",
    "\n",
    "MIN_DOCUMENT_SIZE = 5\n",
    "\n",
    "filter_words = set()\n",
    "if USE_STOPWORDS:\n",
    "    # load stopwords from nltk\n",
    "    filter_words = filter_words.union(set(stopwords.words('english')))\n",
    "    filter_words = filter_words.union(set(stopwords.words('russian')))\n",
    "    # load own stopwords\n",
    "    with open('stopwords_full.txt') as f:\n",
    "        filter_words = filter_words.union(set([word for line in f for word in line.split()]))\n",
    "\n",
    "\n",
    "# input: document: str\n",
    "# output: document: str\n",
    "# make preprocessing of documents, remove useless symbols, remove useless words\n",
    "def preprocessor(s: str):\n",
    "    # all letter to lower case\n",
    "    s = s.lower() \n",
    "    # remove \\n and \\xa0\n",
    "    s = s.replace(\"\\n\", \" \").replace('\\xa0', ' ')\n",
    "    # add space before all hashtags (some people write set of hashtags without spaces)\n",
    "    s = s.replace('#',  ' #')\n",
    "    s = s.replace('_', ' ')\n",
    "    # remove all symbol, which aren't letter or num\n",
    "    s = ''.join(filter(lambda c: c.isalpha() or c.isdigit() or c == '#' or c.isspace(), s))\n",
    "    \n",
    "    # replace all space symbol like space, tab, \\n to simple space and remove double and for space\n",
    "    s = strip_multiple_whitespaces(s)\n",
    "    # remove empty words and words from filtered words \n",
    "    s = ' '.join(list(filter(lambda w:  len(w) > 0 and not (w in filter_words or w.isdigit()), s.split(' '))))\n",
    "    return s\n",
    "\n",
    "\n",
    "cities_counted_posts = dict(map(lambda x: [x, 0], cities))\n",
    "start_time = time.time()\n",
    "old_time = time.time()\n",
    "\n",
    "for city in cities:\n",
    "    for year in years:\n",
    "        # load file and drop documents with empty text\n",
    "        df = pd.read_csv(csv_path(RAW_CAPTION_PATH, city, year)).dropna()\n",
    "        # preprocess of corpus\n",
    "        df['caption'] = df['caption'].apply(preprocessor)\n",
    "        # remove empty documents\n",
    "        df = df[df['caption'].map(lambda t: len(t.split())) >= MIN_DOCUMENT_SIZE]\n",
    "        \n",
    "        languages = []\n",
    "        for s in df['caption']:\n",
    "            languages.append(lang.predict(s)[0][0])\n",
    "        df['lang'] = languages\n",
    "        \n",
    "        cities_counted_posts[city] += len(df)\n",
    "        \n",
    "        # save results\n",
    "        df.to_csv(r'' + csv_path(ClEAN_CAPTION_PATH, city, year), index=False)\n",
    "        print(f\"finished {city} {year}\")\n",
    "        \n",
    "    print(f'finished {city}; time on stage: {time.time() - old_time}; counted posts: {cities_counted_posts[city]}')\n",
    "    old_time = time.time()\n",
    "\n",
    "print(f'completed with time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClNISbTos-PL"
   },
   "source": [
    "Вместо леммитицазии всех докуентов поотдельности можно обработать весь текст, после составить словарь всех слов, леммитизировать все по одному разу и перезаписать текст постов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithm of lemmatize using dictionary of all words in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded words from spb 2016\n",
      "loaded words from spb 2017\n",
      "loaded words from spb 2018\n",
      "loaded words from spb 2019\n",
      "loaded words from spb 2020\n",
      "loaded words from moscow 2016\n",
      "loaded words from moscow 2017\n",
      "loaded words from moscow 2018\n",
      "loaded words from moscow 2019\n",
      "loaded words from moscow 2020\n",
      "loaded words from nyc 2016\n",
      "loaded words from nyc 2017\n",
      "loaded words from nyc 2018\n",
      "loaded words from nyc 2019\n",
      "loaded words from nyc 2020\n",
      "loaded words from london 2016\n",
      "loaded words from london 2017\n",
      "loaded words from london 2018\n",
      "loaded words from london 2019\n",
      "loaded words from london 2020\n",
      "dictionary size: 34414437, words count: 2383693078, time on stage: 1221.226318359375\n",
      "finish of lemmatize; time on stage: 1510.222708940506\n",
      "finished saving of dictionary\n",
      "replaced words for spb 2016\n",
      "replaced words for spb 2017\n",
      "replaced words for spb 2018\n",
      "replaced words for spb 2019\n",
      "replaced words for spb 2020\n",
      "replaced words for moscow 2016\n",
      "replaced words for moscow 2017\n",
      "replaced words for moscow 2018\n",
      "replaced words for moscow 2019\n",
      "replaced words for moscow 2020\n",
      "replaced words for nyc 2016\n",
      "replaced words for nyc 2017\n",
      "replaced words for nyc 2018\n",
      "replaced words for nyc 2019\n",
      "replaced words for nyc 2020\n",
      "replaced words for london 2016\n",
      "replaced words for london 2017\n",
      "replaced words for london 2018\n",
      "replaced words for london 2019\n",
      "replaced words for london 2020\n",
      "finish; time on stage: 1865.500731229782; all time: 4596.950159311295\n"
     ]
    }
   ],
   "source": [
    "# fast lemmatize\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "old_time = time.time()\n",
    "\n",
    "d = defaultdict(int)\n",
    "words_count = 0\n",
    "valid_langs = set(['__label__ru', '__label__en'])\n",
    "\n",
    "# load all words to dictionary\n",
    "for city, year in files:\n",
    "    df = pd.read_csv(csv_path(ClEAN_CAPTION_PATH, city, year)).dropna()\n",
    "    df = df[df.lang.isin(valid_langs)]\n",
    "    for text in df['caption']:\n",
    "        words = text.split(' ')\n",
    "        words_count += len(words)\n",
    "        for word in words:\n",
    "            d[word] += 1\n",
    "    \n",
    "    print(f'loaded words from {city} {year}')\n",
    "\n",
    "print(f'dictionary size: {len(d)}, words count: {words_count}, time on stage: {time.time() - old_time}')\n",
    "old_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# create lemmatized dictionary\n",
    "d_lem = { word: ''.join(my_stem.lemmatize(word)[:-1]) for word in d } # [:-1] for remove \\n after lemmatize\n",
    "print(f'finish of lemmatize; time on stage: {time.time() - old_time}')\n",
    "old_time = time.time()\n",
    "\n",
    "\n",
    "# save dictionary \n",
    "if USE_STOPWORDS:\n",
    "    f = open(DATA_PATH + 'dictionary_sw.txt', 'w')\n",
    "else:\n",
    "    f = open(DATA_PATH + 'dictionary.txt', 'w')\n",
    "\n",
    "for word in d:\n",
    "    f.write(word + ',' + d_lem[word] + ',' + str(d[word]) + '\\n')\n",
    "f.close()\n",
    "\n",
    "print(f'finished saving of dictionary')\n",
    "\n",
    "# replece all words in dataset to lemmatized words\n",
    "for city, year in files:\n",
    "    df = pd.read_csv(csv_path(ClEAN_CAPTION_PATH, city, year)).dropna()\n",
    "    df = df[df.lang.isin(valid_langs)]\n",
    "    df['caption'] = df['caption'].apply(lambda caption: ' '.join(list(map(lambda word: d_lem[word], caption.split()))))\n",
    "    df.to_csv(r'' + csv_path(LEM_CAPTION_PATH, city, year), index=False)\n",
    "    print(f'replaced words for {city} {year}')\n",
    "\n",
    "\n",
    "print(f'finish; time on stage: {time.time() - old_time}; all time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23821976\n",
      "25676956\n"
     ]
    }
   ],
   "source": [
    "unic_words = defaultdict(int)\n",
    "words_count = 0\n",
    "for w in d_lem:\n",
    "    unic_words[d_lem[w]] += d[w]\n",
    "\n",
    "print(len(unic_words))\n",
    "print(len(d_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66280588\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for c in cities_counted_posts:\n",
    "    sum += cities_counted_posts[c]\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23821976\n",
      "4779940\n"
     ]
    }
   ],
   "source": [
    "l = list(unic_words.items())   \n",
    "l.sort(reverse=True, key=lambda item: item[1])\n",
    "\n",
    "\n",
    "print(len(l))\n",
    "l = list(filter(lambda item: item[1] >= 5, l))\n",
    "print(len(l))\n",
    "\n",
    "\n",
    "#for i in range(50):\n",
    "#    print(i, l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30814,
     "status": "ok",
     "timestamp": 1586267032890,
     "user": {
      "displayName": "Михаил Ковальчук",
      "photoUrl": "",
      "userId": "00328138544128199672"
     },
     "user_tz": -180
    },
    "id": "F-NJgdVAw9GK",
    "outputId": "ce50ad29-9f62-4604-b688-99026a1eb366",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28118041\n",
      "4624285\n",
      "0 ('и', 47123490)\n",
      "1 ('в', 40782602)\n",
      "2 ('the', 25321907)\n",
      "3 ('на', 21778329)\n",
      "4 ('and', 17582960)\n",
      "5 ('не', 17461713)\n",
      "6 ('to', 17247785)\n",
      "7 ('с', 17046286)\n",
      "8 ('a', 15060836)\n",
      "9 ('я', 14611226)\n",
      "10 ('что', 13346967)\n",
      "11 ('быть', 12329507)\n",
      "12 ('of', 11710607)\n",
      "13 ('это', 10995701)\n",
      "14 ('вы', 10988061)\n",
      "15 ('in', 10742080)\n",
      "16 ('i', 10707567)\n",
      "17 ('все', 10513121)\n",
      "18 ('по', 10127681)\n",
      "19 ('для', 9605328)\n",
      "20 ('for', 9599197)\n",
      "21 ('а', 9162292)\n",
      "22 ('мы', 9158646)\n",
      "23 ('you', 9025828)\n",
      "24 ('s', 7504245)\n",
      "25 ('как', 7453340)\n",
      "26 ('то', 6994410)\n",
      "27 ('with', 6958631)\n",
      "28 ('is', 6382674)\n",
      "29 ('it', 6364832)\n",
      "30 ('this', 6248305)\n",
      "31 ('my', 6125078)\n",
      "32 ('от', 5921143)\n",
      "33 ('on', 5799243)\n",
      "34 ('за', 5444764)\n",
      "35 ('at', 5426803)\n",
      "36 ('у', 5334559)\n",
      "37 ('но', 5258720)\n",
      "38 ('из', 5241492)\n",
      "39 ('или', 5215885)\n",
      "40 ('наш', 5213585)\n",
      "41 ('к', 5121083)\n",
      "42 ('свой', 4999094)\n",
      "43 ('we', 4945826)\n",
      "44 ('он', 4928514)\n",
      "45 ('день', 4700193)\n",
      "46 ('который', 4685810)\n",
      "47 ('они', 4307775)\n",
      "48 ('мой', 4113984)\n",
      "49 ('год', 4067761)\n",
      "50 ('так', 4057265)\n",
      "51 ('этот', 3943846)\n",
      "52 ('your', 3852516)\n",
      "53 ('our', 3772675)\n",
      "54 ('такой', 3706763)\n",
      "55 ('that', 3626606)\n",
      "56 ('до', 3588484)\n",
      "57 ('all', 3537413)\n",
      "58 ('себя', 3470722)\n",
      "59 ('ты', 3376232)\n",
      "60 ('она', 3364579)\n",
      "61 ('london', 3347956)\n",
      "62 ('если', 3337550)\n",
      "63 ('by', 3325213)\n",
      "64 ('очень', 3315657)\n",
      "65 ('me', 3309093)\n",
      "66 ('be', 3292484)\n",
      "67 ('love', 3285485)\n",
      "68 ('from', 3199570)\n",
      "69 ('ваш', 3174508)\n",
      "70 ('nyc', 3117128)\n",
      "71 ('самый', 3101254)\n",
      "72 ('are', 3080421)\n",
      "73 ('можно', 3064105)\n",
      "74 ('время', 3062662)\n",
      "75 ('о', 3038794)\n",
      "76 ('t', 2993717)\n",
      "77 ('только', 2991713)\n",
      "78 ('еще', 2973736)\n",
      "79 ('один', 2918142)\n",
      "80 ('so', 2882418)\n",
      "81 ('москва', 2865713)\n",
      "82 ('человек', 2860763)\n",
      "83 ('кто', 2732306)\n",
      "84 ('работа', 2721590)\n",
      "85 ('was', 2705541)\n",
      "86 ('new', 2698459)\n",
      "87 ('же', 2615413)\n",
      "88 ('уже', 2604061)\n",
      "89 ('когда', 2588546)\n",
      "90 ('have', 2577165)\n",
      "91 ('новый', 2539734)\n",
      "92 ('ребенок', 2512998)\n",
      "93 ('day', 2488247)\n",
      "94 ('каждый', 2388022)\n",
      "95 ('хотеть', 2312901)\n",
      "96 ('out', 2301586)\n",
      "97 ('цена', 2275271)\n",
      "98 ('мочь', 2225724)\n",
      "99 ('up', 2219719)\n",
      "100 ('what', 2203655)\n",
      "101 ('as', 2200382)\n",
      "102 ('жизнь', 2199735)\n",
      "103 ('чтобы', 2191439)\n",
      "104 ('хороший', 2187051)\n",
      "105 ('but', 2167345)\n",
      "106 ('can', 2134040)\n",
      "107 ('one', 2112287)\n",
      "108 ('фото', 2081314)\n",
      "109 ('просто', 2077093)\n",
      "110 ('друг', 2047207)\n",
      "111 ('какой', 2035487)\n",
      "112 ('вот', 2030505)\n",
      "113 ('заказ', 2009406)\n",
      "114 ('time', 1985416)\n",
      "115 ('сегодня', 1976839)\n",
      "116 ('первый', 1968375)\n",
      "117 ('de', 1918797)\n",
      "118 ('кожа', 1911600)\n",
      "119 ('при', 1880061)\n",
      "120 ('писать', 1868500)\n",
      "121 ('or', 1868280)\n",
      "122 ('happy', 1861026)\n",
      "123 ('m', 1848252)\n",
      "124 ('сделать', 1836684)\n",
      "125 ('любить', 1828595)\n",
      "126 ('us', 1825871)\n",
      "127 ('will', 1814108)\n",
      "128 ('like', 1808389)\n",
      "129 ('любой', 1785510)\n",
      "130 ('more', 1783619)\n",
      "131 ('после', 1780941)\n",
      "132 ('без', 1766223)\n",
      "133 ('делать', 1762315)\n",
      "134 ('get', 1752026)\n",
      "135 ('становиться', 1733668)\n",
      "136 ('today', 1724100)\n",
      "137 ('ждать', 1716921)\n",
      "138 ('спб', 1670971)\n",
      "139 ('доставка', 1670390)\n",
      "140 ('not', 1666634)\n",
      "141 ('директ', 1655177)\n",
      "142 ('всегда', 1641869)\n",
      "143 ('вопрос', 1639379)\n",
      "144 ('размер', 1633352)\n",
      "145 ('just', 1622661)\n",
      "146 ('an', 1620796)\n",
      "147 ('другой', 1604141)\n",
      "148 ('знать', 1580938)\n",
      "149 ('com', 1572211)\n",
      "150 ('маникюр', 1569673)\n",
      "151 ('запись', 1561860)\n",
      "152 ('место', 1552933)\n",
      "153 ('спасибо', 1550403)\n",
      "154 ('раз', 1547101)\n",
      "155 ('даже', 1523344)\n",
      "156 ('волос', 1521933)\n",
      "157 ('со', 1504858)\n",
      "158 ('night', 1501000)\n",
      "159 ('бы', 1494695)\n",
      "160 ('профиль', 1487190)\n",
      "161 ('питер', 1485227)\n",
      "162 ('цвет', 1484003)\n",
      "163 ('тот', 1483429)\n",
      "164 ('do', 1479946)\n",
      "165 ('art', 1470959)\n",
      "166 ('some', 1464633)\n",
      "167 ('нет', 1430100)\n",
      "168 ('может', 1425715)\n",
      "169 ('больше', 1424756)\n",
      "170 ('if', 1406126)\n",
      "171 ('life', 1403150)\n",
      "172 ('хорошо', 1391979)\n",
      "173 ('when', 1391032)\n",
      "174 ('spb', 1386636)\n",
      "175 ('весь', 1382806)\n",
      "176 ('see', 1366033)\n",
      "177 ('красота', 1365363)\n",
      "178 ('newyork', 1363401)\n",
      "179 ('no', 1359667)\n",
      "180 ('мастер', 1359521)\n",
      "181 ('beautiful', 1345240)\n",
      "182 ('под', 1344097)\n",
      "183 ('начинать', 1341207)\n",
      "184 ('now', 1340994)\n",
      "185 ('good', 1314151)\n",
      "186 ('работать', 1312768)\n",
      "187 ('whatsapp', 1309479)\n",
      "188 ('сам', 1304584)\n",
      "189 ('россия', 1297680)\n",
      "190 ('мир', 1296903)\n",
      "191 ('руб', 1291958)\n",
      "192 ('любимый', 1290549)\n",
      "193 ('ru', 1287003)\n",
      "194 ('получать', 1280335)\n",
      "195 ('who', 1272071)\n",
      "196 ('во', 1261052)\n",
      "197 ('любовь', 1255355)\n",
      "198 ('ссылка', 1252326)\n",
      "199 ('about', 1249185)\n",
      "200 ('сейчас', 1231736)\n",
      "201 ('много', 1229082)\n",
      "202 ('great', 1224162)\n",
      "203 ('нужно', 1219385)\n",
      "204 ('here', 1199622)\n",
      "205 ('подарок', 1198169)\n",
      "206 ('photo', 1187356)\n",
      "207 ('ну', 1182765)\n",
      "208 ('да', 1182032)\n",
      "209 ('давать', 1177025)\n",
      "210 ('back', 1173064)\n",
      "211 ('красивый', 1172511)\n",
      "212 ('best', 1170560)\n",
      "213 ('помогать', 1160327)\n",
      "214 ('праздник', 1154668)\n",
      "215 ('food', 1140269)\n",
      "216 ('last', 1137194)\n",
      "217 ('всего', 1135382)\n",
      "218 ('процедура', 1124248)\n",
      "219 ('they', 1117199)\n",
      "220 ('проходить', 1117071)\n",
      "221 ('there', 1106896)\n",
      "222 ('come', 1105683)\n",
      "223 ('шапка', 1093907)\n",
      "224 ('большой', 1093760)\n",
      "225 ('work', 1084306)\n",
      "226 ('петербург', 1078225)\n",
      "227 ('thank', 1067660)\n",
      "228 ('телефон', 1066662)\n",
      "229 ('где', 1066382)\n",
      "230 ('более', 1061449)\n",
      "231 ('приходить', 1059376)\n",
      "232 ('город', 1057946)\n",
      "233 ('how', 1055639)\n",
      "234 ('также', 1053491)\n",
      "235 ('amazing', 1052332)\n",
      "236 ('first', 1039836)\n",
      "237 ('had', 1035466)\n",
      "238 ('music', 1024888)\n",
      "239 ('стоимость', 1016153)\n",
      "240 ('re', 1015356)\n",
      "241 ('make', 1011433)\n",
      "242 ('la', 998563)\n",
      "243 ('go', 995913)\n",
      "244 ('два', 989819)\n",
      "245 ('тело', 989417)\n",
      "246 ('moscow', 989049)\n",
      "247 ('brooklyn', 987839)\n",
      "248 ('поэтому', 985376)\n",
      "249 ('неделя', 984669)\n",
      "250 ('утро', 981829)\n",
      "251 ('y', 978215)\n",
      "252 ('her', 967059)\n",
      "253 ('понимать', 964898)\n",
      "254 ('photography', 964139)\n",
      "255 ('www', 963157)\n",
      "256 ('don', 960550)\n",
      "257 ('has', 957723)\n",
      "258 ('these', 956303)\n",
      "259 ('дело', 955029)\n",
      "260 ('оставаться', 950297)\n",
      "261 ('friends', 944743)\n",
      "262 ('скидка', 944574)\n",
      "263 ('выбирать', 943420)\n",
      "264 ('прекрасный', 942370)\n",
      "265 ('рука', 937066)\n",
      "266 ('their', 936191)\n",
      "267 ('year', 929388)\n",
      "268 ('been', 924529)\n",
      "269 ('direct', 923679)\n",
      "270 ('que', 917334)\n",
      "271 ('говорить', 916352)\n",
      "272 ('fun', 912638)\n",
      "273 ('вид', 910461)\n",
      "274 ('находить', 909206)\n",
      "275 ('сказать', 902590)\n",
      "276 ('качество', 895737)\n",
      "277 ('через', 895322)\n",
      "278 ('fashion', 893428)\n",
      "279 ('санктпетербург', 893069)\n",
      "280 ('час', 892952)\n",
      "281 ('наличие', 892912)\n",
      "282 ('show', 888392)\n",
      "283 ('instagood', 885987)\n",
      "284 ('лицо', 882476)\n",
      "285 ('family', 879897)\n",
      "286 ('only', 877312)\n",
      "287 ('смотреть', 874023)\n",
      "288 ('home', 872724)\n",
      "289 ('дом', 870418)\n",
      "290 ('платье', 868678)\n",
      "291 ('week', 867479)\n",
      "292 ('про', 863258)\n",
      "293 ('e', 860668)\n",
      "294 ('конечно', 857639)\n",
      "295 ('people', 857490)\n",
      "296 ('know', 856827)\n",
      "297 ('д', 854117)\n",
      "298 ('дизайн', 846985)\n",
      "299 ('м', 844551)\n",
      "300 ('именно', 842563)\n",
      "301 ('ve', 839694)\n",
      "302 ('месяц', 836311)\n",
      "303 ('выходной', 834481)\n",
      "304 ('вечер', 834056)\n",
      "305 ('результат', 833868)\n",
      "306 ('summer', 831573)\n",
      "307 ('weekend', 831042)\n",
      "308 ('follow', 821999)\n",
      "309 ('ул', 820069)\n",
      "310 ('city', 818779)\n",
      "311 ('birthday', 818118)\n",
      "312 ('думать', 817831)\n",
      "313 ('ли', 816763)\n",
      "314 ('instagram', 816198)\n",
      "315 ('девочка', 810581)\n",
      "316 ('beauty', 810479)\n",
      "317 ('travel', 808663)\n",
      "318 ('пост', 804932)\n",
      "319 ('том', 804378)\n",
      "320 ('семья', 800145)\n",
      "321 ('much', 798771)\n",
      "322 ('мама', 798219)\n",
      "323 ('russia', 797343)\n",
      "324 ('г', 795027)\n",
      "325 ('пока', 791405)\n",
      "326 ('ведь', 789829)\n",
      "327 ('теперь', 789643)\n",
      "328 ('free', 789506)\n",
      "329 ('проводить', 787729)\n",
      "330 ('идти', 783999)\n",
      "331 ('always', 779499)\n",
      "332 ('образ', 777255)\n",
      "333 ('настроение', 776246)\n",
      "334 ('world', 776004)\n",
      "335 ('лето', 775530)\n",
      "336 ('рассказывать', 775522)\n",
      "337 ('party', 772166)\n",
      "338 ('he', 770973)\n",
      "339 ('got', 769878)\n",
      "340 ('рубль', 769300)\n",
      "341 ('сайт', 766962)\n",
      "342 ('там', 766340)\n",
      "343 ('little', 765822)\n",
      "344 ('стоять', 760232)\n",
      "345 ('over', 760032)\n",
      "346 ('написать', 756982)\n",
      "347 ('тоже', 756838)\n",
      "348 ('магазин', 755595)\n",
      "349 ('live', 755396)\n",
      "350 ('style', 752989)\n",
      "351 ('after', 751652)\n",
      "352 ('look', 751467)\n",
      "353 ('минута', 750422)\n",
      "354 ('комментарий', 749744)\n",
      "355 ('link', 749229)\n",
      "356 ('дома', 749127)\n",
      "357 ('счастие', 747041)\n",
      "358 ('часто', 746275)\n",
      "359 ('his', 743784)\n",
      "360 ('ноготь', 740422)\n",
      "361 ('разный', 740149)\n",
      "362 ('ny', 739349)\n",
      "363 ('видеть', 739192)\n",
      "364 ('хотеться', 738150)\n",
      "365 ('en', 738048)\n",
      "366 ('she', 735762)\n",
      "367 ('цветок', 735747)\n",
      "368 ('весна', 733379)\n",
      "369 ('ни', 733358)\n",
      "370 ('tonight', 729022)\n",
      "371 ('адрес', 726340)\n",
      "372 ('бровь', 725057)\n",
      "373 ('off', 724469)\n",
      "374 ('viber', 722752)\n",
      "375 ('fitness', 722681)\n",
      "376 ('добрый', 722027)\n",
      "377 ('модель', 720910)\n",
      "378 ('глаз', 720858)\n",
      "379 ('создавать', 718313)\n",
      "380 ('стиль', 717459)\n",
      "381 ('sunday', 717435)\n",
      "382 ('принимать', 713795)\n",
      "383 ('интересный', 713075)\n",
      "384 ('way', 710997)\n",
      "385 ('записываться', 706852)\n",
      "386 ('потому', 704065)\n",
      "387 ('also', 703026)\n",
      "388 ('thanks', 702031)\n",
      "389 ('момент', 701787)\n",
      "390 ('иметь', 700462)\n",
      "391 ('скоро', 699365)\n",
      "392 ('решать', 697812)\n",
      "393 ('материал', 696691)\n",
      "394 ('bio', 695333)\n",
      "395 ('тут', 694013)\n",
      "396 ('made', 692902)\n",
      "397 ('жить', 689214)\n",
      "398 ('them', 688412)\n",
      "399 ('next', 687573)\n",
      "400 ('надо', 686012)\n",
      "401 ('несколько', 682701)\n",
      "402 ('девушка', 680743)\n",
      "403 ('отличный', 679546)\n",
      "404 ('hair', 677435)\n",
      "405 ('подходить', 676264)\n",
      "406 ('см', 674240)\n",
      "407 ('последний', 673685)\n",
      "408 ('должный', 673069)\n",
      "409 ('вода', 671910)\n",
      "410 ('дорогой', 670531)\n",
      "411 ('возможность', 670459)\n",
      "412 ('готовый', 669909)\n",
      "413 ('слово', 668183)\n",
      "414 ('вместе', 667170)\n",
      "415 ('использовать', 662582)\n",
      "416 ('into', 662483)\n",
      "417 ('покрытие', 661924)\n",
      "418 ('тренировка', 659264)\n",
      "419 ('photooftheday', 658723)\n",
      "420 ('morning', 658247)\n",
      "421 ('здесь', 657928)\n",
      "422 ('ресница', 657085)\n",
      "423 ('санкт', 655226)\n",
      "424 ('маленький', 653821)\n",
      "425 ('let', 650133)\n",
      "426 ('saintpetersburg', 649685)\n",
      "427 ('am', 648112)\n",
      "428 ('твой', 647561)\n",
      "429 ('второй', 647181)\n",
      "430 ('very', 646199)\n",
      "431 ('o', 643097)\n",
      "432 ('take', 642925)\n",
      "433 ('клиент', 641506)\n",
      "434 ('получаться', 641184)\n",
      "435 ('яркий', 638321)\n",
      "436 ('https', 638107)\n",
      "437 ('york', 637808)\n",
      "438 ('компания', 636323)\n",
      "439 ('женщина', 633150)\n",
      "440 ('почему', 630118)\n",
      "441 ('фотография', 628120)\n",
      "442 ('история', 627240)\n",
      "443 ('помощь', 626529)\n",
      "444 ('every', 626516)\n",
      "445 ('группа', 625987)\n",
      "446 ('still', 625718)\n",
      "447 ('забывать', 624942)\n",
      "448 ('ll', 621243)\n",
      "449 ('проект', 620358)\n",
      "450 ('нужный', 620306)\n",
      "451 ('friday', 619200)\n",
      "452 ('внимание', 617302)\n",
      "453 ('saturday', 615931)\n",
      "454 ('занятие', 613550)\n",
      "455 ('форма', 611857)\n",
      "456 ('гость', 611744)\n",
      "457 ('студия', 611345)\n",
      "458 ('макияж', 610764)\n",
      "459 ('newyorkcity', 609588)\n",
      "460 ('uk', 607763)\n",
      "461 ('everyone', 606658)\n",
      "462 ('repost', 602024)\n",
      "463 ('want', 601878)\n",
      "464 ('d', 601861)\n",
      "465 ('сила', 597032)\n",
      "466 ('полный', 596190)\n",
      "467 ('through', 593804)\n",
      "468 ('спорт', 590534)\n",
      "469 ('before', 589572)\n",
      "470 ('представлять', 589282)\n",
      "471 ('el', 589020)\n",
      "472 ('масло', 587678)\n",
      "473 ('выбор', 586660)\n",
      "474 ('гель', 580919)\n",
      "475 ('здоровье', 580758)\n",
      "476 ('going', 579256)\n",
      "477 ('потом', 578928)\n",
      "478 ('пора', 578200)\n",
      "479 ('сразу', 577744)\n",
      "480 ('приятный', 575991)\n",
      "481 ('состав', 575480)\n",
      "482 ('количество', 574391)\n",
      "483 ('немного', 573276)\n",
      "484 ('класс', 573095)\n",
      "485 ('одежда', 572829)\n",
      "486 ('years', 570634)\n",
      "487 ('посмотреть', 570568)\n",
      "488 ('натуральный', 569568)\n",
      "489 ('центр', 566845)\n",
      "490 ('right', 566587)\n",
      "491 ('часть', 566481)\n",
      "492 ('душа', 566414)\n",
      "493 ('бесплатный', 564240)\n",
      "494 ('малыш', 562616)\n",
      "495 ('заказывать', 562241)\n",
      "496 ('were', 561790)\n",
      "497 ('рождение', 561605)\n",
      "498 ('курс', 561189)\n",
      "499 ('manhattan', 560109)\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH + 'dictionary.txt') as f:\n",
    "    d_list = [[token for token in line.split(',')] for line in f]\n",
    "\n",
    "\n",
    "d_lem = defaultdict(int)\n",
    "\n",
    "\n",
    "for note in d_list:\n",
    "    d_lem[note[1]] += int(note[2])\n",
    "\n",
    "l = list(d_lem.items())   \n",
    "l.sort(reverse=True, key=lambda item: item[1])\n",
    "\n",
    "print(len(l))\n",
    "l = list(filter(lambda item: item[1] > 5, l))\n",
    "print(len(l))\n",
    "\n",
    "for i in range(500):\n",
    "    print(i, l[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28118041\n",
      "5313071\n"
     ]
    }
   ],
   "source": [
    "l = list(d_lem.items())   \n",
    "l.sort(reverse=True, key=lambda item: item[1])\n",
    "\n",
    "print(len(l))\n",
    "l = list(filter(lambda item: item[1] >= 5, l))\n",
    "print(len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_non_alphanum\n",
    "\n",
    "EVENTS_RAW = DATA_PATH + 'events/raw/'\n",
    "EVENTS_CLEANED = DATA_PATH + 'events/cleaned/'\n",
    "               \n",
    "useless_symbols = set(['_', 'ー'])\n",
    "\n",
    "# input: document: str\n",
    "# output: document: str\n",
    "# make preprocessing of documents, remove useless symbols and numbers\n",
    "def cleaner(s: str):\n",
    "    # all letter to lower case\n",
    "    s = s.lower() \n",
    "    \n",
    "    # remove all symbol, which aren't letter or num\n",
    "    s = strip_non_alphanum(s)\n",
    "    # strip_non_alphanum don't remove '_' symbol\n",
    "    s = ''.join(map(lambda c: ' ' if c in useless_symbols else c, s))\n",
    "\n",
    "    # replace all space symbol like space, tab, \\n to simple space and remove double and for space\n",
    "    s = strip_multiple_whitespaces(s)\n",
    "    # remove empty words and words from filtered words \n",
    "    s = ' '.join(filter(lambda w:  not w.isdigit(), s.split(' ')))\n",
    "    return s\n",
    "\n",
    "\n",
    "# load file and drop documents with empty text\n",
    "df = pd.concat([pd.read_csv(EVENTS_RAW + 'spb_events.csv'), pd.read_csv(EVENTS_RAW + 'moscow_events.csv')])\n",
    "# preprocess of corpus\n",
    "df['description'] = df['captions'].apply(cleaner)\n",
    "\n",
    "# save results\n",
    "df.to_csv(r'' + EVENTS_CLEANED + 'events.csv', index=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words = set()\n",
    "# load stopwords from nltk\n",
    "filter_words = filter_words.union(set(stopwords.words('english')))\n",
    "filter_words = filter_words.union(set(stopwords.words('russian')))\n",
    "# load own stopwords\n",
    "with open('stopwords_full.txt') as f:\n",
    "    filter_words = filter_words.union(set([word for line in f for word in line.split()]))\n",
    "    \n",
    "df['description'] = df['description'].apply(lambda s: ' '.join(filter(lambda w: not w in filter_words, s.split())))\n",
    "df.to_csv(r'' + EVENTS_PATH + 'events_clean_sw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'dictionary.txt') as f:\n",
    "    d_list = [[token for token in line.split(',')] for line in f]\n",
    "\n",
    "d_lem = defaultdict(str)\n",
    "for note in d_list:\n",
    "    d_lem[note[0]] = note[1]\n",
    "\n",
    "def lemmatize(word: str):\n",
    "    return d_lem[word] if word in d_lem else ''.join(my_stem.lemmatize(word))\n",
    "\n",
    "df = pd.read_csv(EVENTS_PATH + 'events_clean_sw.csv')\n",
    "df['description'] = df['description'].apply(lambda s: ' '.join(map(lemmatize, s.split())))\n",
    "df.to_csv(r'' + EVENTS_PATH + 'events_lem_sw.csv', index=False)\n",
    "\n",
    "df = pd.read_csv(EVENTS_PATH + 'events_clean.csv')\n",
    "df['description'] = df['description'].apply(lambda s: ' '.join(map(lemmatize, s.split())))\n",
    "df.to_csv(r'' + EVENTS_PATH + 'events_lem.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(EVENTS_PATH + 'events_clean.csv')\n",
    "df['description'] = df['description'].apply(lambda s: ' '.join(map(lemmatize, s.split())))\n",
    "df.to_csv(r'' + EVENTS_PATH + 'events_lem.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMZsRMlgE+83bZ7K7jNXAb5",
   "machine_shape": "hm",
   "name": "filter_caption.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
