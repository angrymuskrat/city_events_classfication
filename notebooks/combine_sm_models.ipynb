{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MODEL_NAME = 'ft1_ru'\n",
    "DATA_PATH = '/data/'\n",
    "USE_COSINE = False\n",
    "SUFFIX = '_norm' if USE_COSINE else ''\n",
    "SEM_MODEL_PATH = f'{DATA_PATH}models/sm_{MODEL_NAME}{SUFFIX}/'\n",
    "\n",
    "use_hashtags = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/models/sm_ft1_ru/\n"
     ]
    }
   ],
   "source": [
    "print(SEM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16581750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>idf_lem</th>\n",
       "      <th>count_usages_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>это</td>\n",
       "      <td>1.780131</td>\n",
       "      <td>10734209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>не</td>\n",
       "      <td>1.504183</td>\n",
       "      <td>17255993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>зус</td>\n",
       "      <td>13.547780</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>зять</td>\n",
       "      <td>9.916372</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>просто</td>\n",
       "      <td>3.038876</td>\n",
       "      <td>2038966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lemmatized    idf_lem  count_usages_lem\n",
       "0        это   1.780131          10734209\n",
       "1         не   1.504183          17255993\n",
       "2        зус  13.547780                53\n",
       "3       зять   9.916372              2089\n",
       "4     просто   3.038876           2038966"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_hashtags:\n",
    "    dict_path = DATA_PATH + \"captions/dict_lem.csv\"\n",
    "else:\n",
    "    dict_path = DATA_PATH + \"captions/dict_lem_without_hash.csv\"\n",
    "\n",
    "df = pd.read_csv(dict_path).dropna()\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928769"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples = list(range(10, 151, 10)) + list(range(200, 1001, 100))\n",
    "samples = list(range(30, 101, 10)) + [150, 200, 250, 300, 400, 500]\n",
    "# samples = list(range(10, 151, 1)) + list(range(200, 1001, 50)) + [1250, 1500, 1750, 2000]\n",
    "#samples = [50, 75, 100, 125, 150, 200, 300, 400, 500]\n",
    "# samples = list(range(10, 191, 10)) + [512, 1024, 2048]\n",
    "def build_w2l(n_clusters):\n",
    "    path = f'{SEM_MODEL_PATH}{n_clusters}/'\n",
    "    with open(f'{path}labels.txt') as f:\n",
    "        labels = [line.split(',') for line in f]\n",
    "    \n",
    "    # filtering all exceptions (each row in labels.txt should look like 'word,label')\n",
    "    labels = [tokens for tokens in labels if len(tokens) == 2] \n",
    "    # cast words labels to int\n",
    "    labels = [(word, int(label[:-1])) for word, label in labels]\n",
    "    # building dict: word -> label\n",
    "    w2l = {}\n",
    "    for word, label in labels:\n",
    "        w2l[word] = label\n",
    "    return w2l\n",
    "\n",
    "w2l_init = build_w2l(samples[0])\n",
    "df = df[df.lemmatized.isin(w2l_init)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_clusters in samples:\n",
    "    w2l = build_w2l(n_clusters)\n",
    "    df = df[df.lemmatized.isin(w2l)]\n",
    "    df[str(int(n_clusters))] = [w2l[lemmed] for lemmed in df.lemmatized]\n",
    "\n",
    "df.to_csv(r'' + SEM_MODEL_PATH + 'labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/data/models/sm_ft1_ru/*2': No such file or directory\n",
      "rm: cannot remove '/data/models/sm_ft1_ru/*4': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r {SEM_MODEL_PATH}*0\n",
    "!rm -r {SEM_MODEL_PATH}*2\n",
    "!rm -r {SEM_MODEL_PATH}*4\n",
    "!rm -r {SEM_MODEL_PATH}*5\n",
    "!rm -r {SEM_MODEL_PATH}*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r /data/tmp/sm_wv3_ru_norm_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.lemmatized[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{SEM_MODEL_PATH}{n_clusters}/'\n",
    "    \n",
    "with open(f'{path}labels.txt') as f:\n",
    "    labels = [line.split(',') for line in f]\n",
    "    \n",
    "# filtering all exceptions (each row in labels.txt should look like 'word,label')\n",
    "labels = [tokens for tokens in labels if len(tokens) == 2] \n",
    "# cast words labels to int\n",
    "labels = [(word, int(label[:-1])) for word, label in labels]\n",
    "# building dict: word -> label\n",
    "w2l = {}\n",
    "for word, label in labels:\n",
    "    w2l[word] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
