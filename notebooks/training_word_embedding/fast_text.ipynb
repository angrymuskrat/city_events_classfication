{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '/data/'\n",
    "MODEL_PATH = DATA_PATH + 'models/ft5_ru/'\n",
    "SOURCE_PATH = DATA_PATH + 'captions/lem/'\n",
    "\n",
    "cities = ['moscow', 'spb']#, 'nyc', 'london']\n",
    "years = ['2016', '2017', '2018', '2019', '2020']\n",
    "files = []\n",
    "for city in cities:\n",
    "    for year in years:\n",
    "        files.append([city, year])\n",
    "\n",
    "def csv_path(path, city, year):\n",
    "    return path + city + '_posts_' + year + '.csv'\n",
    "\n",
    "valid_langs = set(['__label__ru'])\n",
    "\n",
    "USE_PRETRAINED_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.24 GiB for an array with shape (2000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eb54383da7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_facebook_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'wiki.ru.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'success, vocab: {len(model.wv.vocab)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, sg, hs, size, alpha, window, min_count, max_vocab_size, word_ngrams, sample, seed, workers, min_alpha, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, min_n, max_n, sorted_vocab, bucket, trim_rule, batch_words, callbacks, compatible_hash)\u001b[0m\n\u001b[1;32m    485\u001b[0m             sorted_vocab=bool(sorted_vocab), null_word=null_word, ns_exponent=ns_exponent)\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastTextTrainables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashfxn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[0;34m(self, hs, negative, wv, update, vocabulary)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastTextTrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_ngrams_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_ngrams_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36minit_ngrams_weights\u001b[0;34m(self, wv, update, vocabulary)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \"\"\"\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_ngrams_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_vocab_lockf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_ngrams_lockf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_ngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36minit_ngrams_weights\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0;31m#    time because the vocab is not initialized at that stage.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_ngrams_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_vocab_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.24 GiB for an array with shape (2000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "!mkdir {MODEL_PATH}\n",
    "class MyCorpus(object):\n",
    "    iter = 0\n",
    "    def __iter__(self):\n",
    "        self.iter += 1\n",
    "        for city in cities:\n",
    "            for year in years:\n",
    "                df = pd.read_csv(csv_path(SOURCE_PATH, city, year))\n",
    "                df = df[df.lang.isin(valid_langs)]\n",
    "                for s in df['caption']:\n",
    "                    yield s.split()\n",
    "                              \n",
    "            print(f'iter {self.iter} for {city} completed')\n",
    "                \n",
    "        print(f'\\niter {self.iter} completed\\n')\n",
    "\n",
    "sentences = MyCorpus()\n",
    "\n",
    "# dimension 300, with character n-grams of length 5, a window of size 5 and 10 negatives\n",
    "# https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    model =  gensim.models.fasttext.load_facebook_model(MODEL_PATH + 'wiki.ru.bin')\n",
    "else:\n",
    "    model = FastText(size=300, window=15, min_count=10, word_ngrams=2, negative=20, workers=20)\n",
    "print(f'success, vocab: {len(model.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('building vocab\\n')\n",
    "if USE_PRETRAINED_MODEL:\n",
    "    model.build_vocab(sentences=MyCorpus(), update=True)\n",
    "else:\n",
    "    model.build_vocab(sentences=MyCorpus())\n",
    "total_examples = model.corpus_count\n",
    "print(f'\\ncorpus count: {total_examples}; vocab: {len(model.wv.vocab)}\\nend of building')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start training\\n')\n",
    "model.train(sentences=MyCorpus(), total_examples=total_examples, epochs=40)\n",
    "print(f'\\nend of training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH + 'mdl')\n",
    "\n",
    "f = open(MODEL_PATH + 'description.txt', 'w')\n",
    "f.write('date: 08.05\\n')\n",
    "f.write('params: size=300, min_count=1, window=5, negative=10, word_ngrams=5, epochs=5\\n')\n",
    "f.write(f'sourse: {SOURCE_PATH}\\n')\n",
    "f.write('cities: moscow, spb; only russian\\n')\n",
    "f.write('without deleting hastags \\n')\n",
    "print('success')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80805814 8марта 23февраля\n",
      "0.27433598 8марта выставка\n",
      "0.48473305 8марта рождество\n",
      "0.37270707 8марта свадьба\n",
      "0.53255945 8марта 9мая\n",
      "0.24352027 8марта сплин\n",
      "0.49690336 сплин слот\n",
      "0.57352257 сплин rammstein\n",
      "0.32789782 сплин рождество\n",
      "0.2025525 сплин свадьба\n",
      "0.20832917 сплин маникюр\n",
      "0.26205045 сплин спб\n",
      "0.65433633 сплин ддт\n",
      "0.60260904 сплин концерт\n",
      "0.5566946 сплин песня\n",
      "0.5037586 сплин нойз\n",
      "0.6719568 зенит ска\n",
      "0.61660373 зенит хоккей\n",
      "0.6510804 зенит баскетбол\n",
      "0.39403272 зенит сплин\n",
      "0.28050265 зенит 8марта\n",
      "0.30077258 зенит рождество\n",
      "0.7404321 зенит футбол\n",
      "0.6728875 зенит арена\n",
      "0.48191747 зенит мяч\n",
      "0.6609002 зенит гол\n",
      "0.79878855 зенит спартак\n",
      "0.19693191 зенит маникюр\n",
      "0.16906635 зенит сушь\n",
      "0.37501115 зенит тенис\n",
      "0.46583143 тенис волебол\n",
      "0.22568047 тенис марафон\n",
      "0.23857808 тенис лыжа\n",
      "0.38073522 зенит спорт\n",
      "0.50807 тенис спорт\n",
      "0.5412748 баскетбол спорт\n",
      "0.6130132 итмо университет\n"
     ]
    }
   ],
   "source": [
    "with open('tests.txt') as f:\n",
    "    tests = [[word for word in line.split()] for line in f]\n",
    "\n",
    "for test in tests:\n",
    "    print(model.wv.similarity(test[0], test[1]), test[0], test[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77465004 8марта 23февраля\n",
      "0.26400387 8марта выставка\n",
      "0.44828498 8марта рождество\n",
      "0.3088644 8марта свадьба\n",
      "0.47429362 8марта 9мая\n",
      "0.19591044 8марта сплин\n",
      "0.3752808 сплин слот\n",
      "0.5153809 сплин rammstein\n",
      "0.2440366 сплин рождество\n",
      "0.17200556 сплин свадьба\n",
      "0.12906846 сплин маникюр\n",
      "0.14062892 сплин спб\n",
      "0.6133099 сплин ддт\n",
      "0.55933976 сплин концерт\n",
      "0.56913275 сплин песня\n",
      "0.50104636 сплин нойз\n",
      "0.6024536 зенит ска\n",
      "0.5754436 зенит хоккей\n",
      "0.5914444 зенит баскетбол\n",
      "0.32471004 зенит сплин\n",
      "0.22286703 зенит 8марта\n",
      "0.24321106 зенит рождество\n",
      "0.7139603 зенит футбол\n",
      "0.6243685 зенит арена\n",
      "0.42467847 зенит мяч\n",
      "0.6441635 зенит гол\n",
      "0.7541795 зенит спартак\n",
      "0.13084683 зенит маникюр\n",
      "0.11200154 зенит сушь\n",
      "0.36260748 зенит тенис\n",
      "0.43142712 тенис волебол\n",
      "0.16143346 тенис марафон\n",
      "0.4329789 тенис лыжа\n",
      "0.29186195 зенит спорт\n",
      "0.43753514 тенис спорт\n",
      "0.5064553 баскетбол спорт\n",
      "0.6249611 итмо университет\n"
     ]
    }
   ],
   "source": [
    "with open('tests.txt') as f:\n",
    "    tests = [[word for word in line.split()] for line in f]\n",
    "\n",
    "for test in tests:\n",
    "    print(model.wv.similarity(test[0], test[1]), test[0], test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
